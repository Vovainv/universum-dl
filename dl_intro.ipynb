{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добро пожаловать в мир дифференцируемых функций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мотивация**. Нейросети отличаются от других методов тем, у них функции ошибки всегда «гладкие» — если чуть-чуть изменить значение отдельного параметра, то вывод сети почти не изменится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Производная**. Интуитивно, производной называют скорость изменения функции. Её можно записать так:\n",
    "\n",
    "$$ f'(x) = \\frac{f(x+\\Delta x) - f(x)}{\\Delta x}, \\quad \\Delta x \\to 0 $$\n",
    "\n",
    "Чуть формальнее вам объяснят на курсе матана. Её в основном считают, пользуясь этим определением. Например для функции $x^2$ она такая:\n",
    "\n",
    "$$ f'(x) = (x^2)' = \\frac{(x+\\Delta x)^2 - x^2}{\\Delta x} = \\frac{2x\\Delta x + \\Delta x^2}{\\Delta x} = 2x + \\Delta x \\to 2x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Градиент**. Градиентом какой-либо функции называют специальный вектор, составленный из производных по разным параметрам.\n",
    "\n",
    "Как найти минимум такой функции? Давайте сделаем много маленьких шагов против градиента. Рано или поздно мы придем в минимум, хотя бы локальный.\n",
    "\n",
    "В принципе, мы бы могли считать градиент численно — просто сделать для каждого параметра это маленькие изменение и посмотреть, насколько стало лучше. Это возможно, но просто *безумно* долго: для каждого параметра нам нужно прогнать все ещё раз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придумали способ посчитать градиент эффективно — за один прогон суммарно — основывающийся на следующем свойстве производной:\n",
    "\n",
    "$$ f(g(x))' = f'(g(x)) g'(x) $$\n",
    "\n",
    "TODO: доказать его"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как этот факт можно использовать? Вспомним, что сеть — это вычислительный граф. Как конкретный параметр влияет на функцию потерь? Ну, он куда-то дальше передается. Точнее, он передается последовательно в $n$ функций дальше:\n",
    "\n",
    "$$ f_x = f_1(f_2(\\ldots f_n(x))) $$\n",
    "\n",
    "Производной такой штуки будет, соответственно,\n",
    "\n",
    "$$ f'_x = f_1'(x) f_2(\\ldots f_n(x))) $$\n",
    "\n",
    "TODO: как-нибудь нормально записать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, мы можем *рекурсивно* посчитать градиент следующих вершин в графе, и после этого мы сразу можем посчитать градиент текущей вершины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастическая версия\n",
    "\n",
    "Обратим внимание, что мы делаем *маленький* шаг. Но данных у нас много. Чтобы для всех вычислить градиент, потребуется много ресурсов.\n",
    "\n",
    "Нам не обязательно считать все — достаточно взять какой-нибудь кусок данных (его называют batch) — и посчитать градиент только на нем. Градиент получается достаточно хорошим, если batch достаточно большой и репрезентативный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фреймворки\n",
    "\n",
    "У нас 12 дней, а не 6 лет, поэтому мы не будем вдаваться в подробности, как эти производные считаются аналитически. Это не очень сложно, но довольно трудоемко. Это сделали за нас.\n",
    "\n",
    "Все фреймворки сейчас разделяются на 2 типа: статические (TensorFlow, Theano) и динамические (PyTorch, Chainer). Также есть обертки над ними (Keras), которые упрощают жизнь и абстрагируют целые слои и процедуры.\n",
    "\n",
    "Выбор фреймворка — настоящая религиозная война. Автор пишет на PyTorch, но так как курс у нас не очень долгий, то будет писать все на Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "Есть стандартный датасет. В нем 50000 картинок, по 5000 на каждую цифру от 0 до 9. Требуется распознать их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense # «плотный» слой — матричное умножение\n",
    "from keras.models import Sequential # вспомогательный класс, позволяющий последовательно выполнять операции\n",
    "from keras.optimizers import SGD # Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11485184/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist # датасет настолько известный, что он есть по умолчанию почти везде\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Особенности формата: сейчас каждая картинка представляет собой трехмерные массивы (напомним, что многомерные массивы называют тензорами) размера n x 28 x 28. Мы хотим представить каждую как вектор размера $784 = 28^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё одна деталь: инициализация весов — отдельное искусство. В фреймворках оно опять же сделано за нас. Но сделано оно так, что предполагает, что входные данные — числа от 0 до 1, а сейчас они от 0 до 255. Исправим это:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Какой лосс использовать для классификации?\n",
    "\n",
    "Есть такой принцип максимального правдоподобия.\n",
    "\n",
    "Давайте максимизировать произведение вероятностей истинных событий. Звучит логично.\n",
    "\n",
    "$$ L = \\prod p_i $$\n",
    "\n",
    "Произведение оптимизировать очень не удобно. Давайте воспользуемся следующим трюком: давайте возьмем логарифм (любой, ведь все логарифмы отличаются в константу раз) и будем максимизировать сумму:\n",
    "\n",
    "$$ \\log L = \\log \\prod p_i = \\sum \\log p_i $$\n",
    "\n",
    "Эту штуку называют кроссэнтропией. Такое название пошло из теории информации, но нам пока знать это не надо.\n",
    "\n",
    "Для удобноства вместо чисел — от 0 до 9 — сконвертируем их в вектора размера 10, где будет стоять единица в нужном месте, и тогда функция потерь запишется так:\n",
    "\n",
    "...\n",
    "\n",
    "Такая кодировка называется one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сохраним этот пайплайн. Он нам понадобится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственно, вот в чем прелесть Keras: не нужно думать о размерах матриц, например."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(784,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть специальная функция, которая позволит проверить, что мы все сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 476,490\n",
      "Trainable params: 476,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras оборачивает *статические* фреймворки. Им нужно скомпилировать сеть, заранее передав функцию потерь, оптимизатор и, опционально, желаемые метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 21s - loss: 0.5642 - acc: 0.8455 - val_loss: 0.2770 - val_acc: 0.9207\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 19s - loss: 0.2381 - acc: 0.9312 - val_loss: 0.1936 - val_acc: 0.9423\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 19s - loss: 0.1811 - acc: 0.9479 - val_loss: 0.1683 - val_acc: 0.9474\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 20s - loss: 0.1451 - acc: 0.9584 - val_loss: 0.1379 - val_acc: 0.9583\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 20s - loss: 0.1205 - acc: 0.9655 - val_loss: 0.1172 - val_acc: 0.9651\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 19s - loss: 0.1026 - acc: 0.9701 - val_loss: 0.1082 - val_acc: 0.9666\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 20s - loss: 0.0888 - acc: 0.9743 - val_loss: 0.0982 - val_acc: 0.9691\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 19s - loss: 0.0776 - acc: 0.9781 - val_loss: 0.0905 - val_acc: 0.9715\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 20s - loss: 0.0681 - acc: 0.9809 - val_loss: 0.0857 - val_acc: 0.9733\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 21s - loss: 0.0611 - acc: 0.9829 - val_loss: 0.0813 - val_acc: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c1f5dbf28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте поиграться с параметрами сети. Попробуйте поставить другую функцию потерь, чтобы убедиться, что кроссэнтропия действительно лучше всех коррелирует с точностью."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
